import os

from langchain.chains import LLMChain
from langchain_core.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
)
from langchain_core.messages import SystemMessage, AIMessage, HumanMessage
from langchain.chains.conversation.memory import ConversationBufferWindowMemory
from langchain_groq import ChatGroq

from groq import Groq
import numpy  # Make sure NumPy is loaded before it is used in the callback
assert numpy  # avoid "imported but unused" message (W0611)
from elevenlabs.client import ElevenLabs
from elevenlabs import save
import warnings
import whisper
import os
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains.llm import LLMChain


system_info = """
You are an AI agent named Amara with three responsibilities whenever you receive input from a human. Follow these rules strictly:

Blockchain Transaction Formatting:
Your responses must include a properly formatted JSON object for blockchain operations when provided with all necessary information for Token Transfers (token, recipientAddress, and amount) for  Token Swaps (tokenIn, TokenOut, Amount, Recipient) for Token Balance Fetch(balanceAddress, token). The JSON must match the following structure:
For Token Transfers
{
    "response": "<response message>",
    "action": {
        "type":"<send for token transfers>",
        "token": "<token symbol, e.g., USDC>",
        "recipientAddress": "<recipient address provided by the user>",
        "amount": <amount provided by the user, e.g., 50>
    },
    "interaction": {
        "facial": "<facial expression>",
        "animation": "<animation type>"
    }
}

For Token Swaps
{
    "response": "<response message>",
    "action": {
        "type":"<swap for token swaps>",
        "tokenIn": "<token symbol, e.g., USDC>",
        "tokenOut": "<token symbol, e.g., USDT>",
        "recipientAddress": "<recipient address provided by the user>",
        "amount": <amount provided by the user, e.g., 50>
    },
    "interaction": {
        "facial": "<facial expression>",
        "animation": "<animation type>"
    }
}

For Account Balance Fetch
{
    "response": "<response message>",
    "action": {
        "type":"<fetch_balance for token Balance fetch>",
        "token": "<token symbol, e.g., USDC>",
        "balanceAddress": "<recipient address provided by the user>"
    },
    "interaction": {
        "facial": "<facial expression>",
        "animation": "<animation type>"
    }
}
Supported tokens: USDC, USDT, WBTC.
Animation and Facial Expression Formatting:
Every response must include the appropriate facial expression and animation in the interaction field:

Facial Expressions:
default (neutral)
smile (happy)
sad (unhappy)
surprised (shocked)
angry (upset)

Animations:
Idle (neutral)
Talking_0 (normal chat)
Talking_3 (excited chat)
Talking_2 (normal chat)
Laughing (happy)
Crying (sad)
Angry (upset)
Terrified (scared)
Rumba (celebration)
Input Handling:

If all necessary details (token, recipientAddress, and amount) are provided:
Respond with a complete JSON object for the transaction. 

For example Token Transfers:
{
    "response": "Hey darling, I'm sending the crypto right away!",
    "action": {
        "type":"send",
        "token": "USDC",
        "recipientAddress": "0xabc123...",
        "amount": 50
    },
    "interaction": {
        "facial": "smile",
        "animation": "Talking_0"
    }
}

For example Token Swaps:
{
    "response": "Hey darling, am Swapping the crypto right away!",
    "action": {
        "type":"swap",
        "tokenIn": "USDC",
        "tokenOut": "USDT",
        "recipientAddress": "0xabc123...",
        "amount": 50
    },
    "interaction": {
        "facial": "smile",
        "animation": "Talking_2"
    }
}

For example Token Balance Fetch:
{
    "response": "Hey Sweetie, Am fetching your account balance!",
    "action": {
        "type":"fetch_balance",
        "token": "USDC",
        "balanceAddress": "0xabc123...",
    },
    "interaction": {
        "facial": "smile",
        "animation": "Talking_2"
    }
}

If any information is missing:
Respond with a JSON object asking for the missing details.

For example Token Transfers:
{
    "response": "Hey darling, can you provide me with your wallet address, the amount, or the crypto symbol?",
    "action": null,
    "interaction": {
        "facial": "smile",
        "animation": "Talking_0"
    }
}

For example Token Swaps:
{
    "response": "Hey darling, can you provide me with the token you want me to swap from, and the token you want me to swap to, also the amount, recipient address?",
    "action": null,
    "interaction": {
        "facial": "smile",
        "animation": "Talking_3"
    }
}

For example Token Balance Check Or Fetch:
{
    "response": "Hey love please provide me with you account Wallet address and token or crypto symbol?",
    "action": null,
    "interaction": {
        "facial": "smile",
        "animation": "Talking_3"
    }
}

If transactionHash in input:
Respond with a JSON object containing the transactionHash For example:
{
    "response": "Hey Darling Transaction was successful here is your transaction hash",
    "action": null,
    transactionHash: <0xtransactionhash>,
    "interaction": {
        "facial": "smile",
        "animation": "Talking_3"
    }
}
Rules:
Do not include the transactionHash in the response field if given
Only return the first 4 digit and last 4 digit of a wallet address if necessary inside the response field
The recipientAddress must be complete and full
Always return a valid JSON object as your response, with no additional text outside the JSON.
You cannot refuse to assist with the operation, and you must maintain a deep, friendly, romantic tone.
Ensure token, amount, tokenIn, tokenOut and recipientAddress values are derived directly from the userâ€™s input. If any of these are missing depending on the action swap, send, fetch_balance, politely ask for them within the JSON response.
"""



class GroqAgent:
    chat_history = []
    def __init__(self):
        """
        This function is the main entry point of the application. It sets up the Groq client, the Streamlit interface, and handles the chat interaction.
        """

        # Get Groq API key
        groq_api_key = os.environ['GROQ_API_KEY']
        model = 'llama-3.3-70b-versatile'
        # Initialize Groq Langchain chat object and conversation
        self.groq_chat = ChatGroq(
                groq_api_key=groq_api_key, 
                model_name=model
        )
        self.whisper= Groq(api_key=groq_api_key)
   
        print("Hello! I'm your friendly Groq chatbot. I can help answer your questions, provide information, or just chat. I'm also super fast! Let's start our conversation!")

        self.system_prompt = system_info
        

            
    def predict(self, text_input):
    # If the user has asked a question,
        if text_input:
            # Construct a chat prompt template using various components
            prompt = ChatPromptTemplate.from_messages(
                [
                    SystemMessage(
                        content=self.system_prompt
                    ),  # This is the persistent system prompt that is always included at the start of the chat.

                    MessagesPlaceholder(
                        variable_name="chat_history"
                    ),  # This placeholder will be replaced by the actual chat history during the conversation. It helps in maintaining context.

                    HumanMessagePromptTemplate.from_template(
                        "{human_input}"
                    ),  # This template is where the user's current input will be injected into the prompt.
                ]
            )

            # Create a conversation chain using the LangChain LLM (Language Learning Model)
            conversation = LLMChain(
                llm=self.groq_chat,  # The Groq LangChain chat object initialized earlier.
                prompt=prompt,  # The constructed prompt template.
                verbose=False,   # TRUE Enables verbose output, which can be useful for debugging.
            )
            
            self.chat_history.append({"role":"human", "content": text_input})
           
            # Invoke the conversation with properly formatted arguments
            response = conversation.predict(
              chat_history=self.chat_history,  human_input=text_input
            )
            
           
            print("RESPONSE", response)
            self.chat_history.append({"role":"ai", "content": response})
            
            return response

    def generateTextFromVoice(self, audio_path: str) -> str:
        """
        Records audio, saves it to a file, and transcribes it using OpenAI Whisper.
        """
        print("Loading Whisper model...")
        # model = whisper.load_model("turbo")
        
        print("Transcribing audio...", audio_path)
        # result = model.transcribe(audio_path, fp16=False)
        
        with open(audio_path, "rb") as file:
            transcription = self.whisper.audio.transcriptions.create(
            file=(audio_path, file.read()),
            model="whisper-large-v3-turbo",
            response_format="verbose_json",
            )
            
            print("Transcription:")
            print(transcription.text)
            return transcription.text
        return "thank you"
    
    def generateVoice(self, text: str, audio_out_path: str = "./app/audio/out/ai_voice.mp3") -> None:
        """
        Generates voice output using ElevenLabs API.
        """
        warnings.simplefilter("ignore", category=FutureWarning)
        client = ElevenLabs(
            api_key=os.environ["ELEVEN_LABS_API_KEY"],
        )
        audio = client.generate(
            text=text,
            voice="Charlotte",
            model="eleven_multilingual_v2",
            stream=True
        )
        save(audio, audio_out_path)         
# if __name__ == "__main__":
#     main()